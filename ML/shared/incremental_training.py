#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
"""

import os
import sys
import json
import time
import logging
from datetime import datetime
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –ø—Ä–æ–µ–∫—Ç–∞–º
sys.path.append('human_behavior_prediction')
sys.path.append('biochemistry_molecules')
sys.path.append('small_ml_project')

from human_behavior_prediction.main import HumanBehaviorPredictionPipeline
from biochemistry_molecules.main import MolecularPropertyPredictionPipeline
from small_ml_project.main import MLPipeline

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('incremental_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class IncrementalTrainer:
    def __init__(self):
        self.training_history = {}
        self.load_training_history()
    
    def load_training_history(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        if os.path.exists('training_history.json'):
            with open('training_history.json', 'r') as f:
                self.training_history = json.load(f)
        else:
            self.training_history = {
                'human_behavior': {'cycles': 0, 'last_training': None},
                'molecular': {'cycles': 0, 'last_training': None},
                'small_ml': {'cycles': 0, 'last_training': None}
            }
    
    def save_training_history(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        with open('training_history.json', 'w') as f:
            json.dump(self.training_history, f, indent=2)
    
    def incremental_train_human_behavior(self, n_samples=5000, cycles=3):
        """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è"""
        logger.info("=" * 60)
        logger.info("–ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ü–†–û–ì–ù–û–ó–ê –ü–û–í–ï–î–ï–ù–ò–Ø")
        logger.info("=" * 60)
        
        try:
            pipeline = HumanBehaviorPredictionPipeline()
            
            for cycle in range(cycles):
                logger.info(f"–¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è {cycle + 1}/{cycles}")
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                new_data = pipeline.data_generator.generate_dataset(n_samples=n_samples)
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
                existing_data_path = Path('human_behavior_prediction/data/human_behavior_data.csv')
                if existing_data_path.exists():
                    existing_data = pipeline.load_data()
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                    combined_data = pipeline.data_generator.data_generator.create_dataset(
                        n_samples=len(existing_data) + len(new_data)
                    )
                else:
                    combined_data = new_data
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                combined_data.to_csv(existing_data_path, index=False)
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
                X, y = pipeline.prepare_features('will_purchase')
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                models_dir = Path('human_behavior_prediction/models')
                if models_dir.exists() and any(models_dir.glob('*.pkl')):
                    pipeline.model_trainer.load_models()
                
                # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏
                X_train, X_val, X_test, y_train, y_val, y_test = pipeline.model_trainer.prepare_data(X, y)
                
                # –û–±—É—á–∞–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
                for model_name in ['xgboost', 'lightgbm', 'neural_network']:
                    if model_name == 'neural_network':
                        model = pipeline.model_trainer.train_neural_network(
                            X_train, y_train, X_val, y_val, 'classification'
                        )
                    elif model_name == 'xgboost':
                        model = pipeline.model_trainer.train_xgboost(
                            X_train, y_train, X_val, y_val, 'classification'
                        )
                    elif model_name == 'lightgbm':
                        model = pipeline.model_trainer.train_lightgbm(
                            X_train, y_train, X_val, y_val, 'classification'
                        )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏
                pipeline.model_trainer.save_models()
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏
                pipeline.evaluate_models(X_test, y_test)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
                self.training_history['human_behavior']['cycles'] += 1
                self.training_history['human_behavior']['last_training'] = datetime.now().isoformat()
                
                logger.info(f"‚úÖ –¶–∏–∫–ª {cycle + 1} –∑–∞–≤–µ—Ä—à–µ–Ω")
            
            self.save_training_history()
            logger.info("‚úÖ –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏: {e}")
            return False
    
    def incremental_train_molecular(self, dataset_name='tox21', cycles=2):
        """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤"""
        logger.info("=" * 60)
        logger.info("–ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ú–û–õ–ï–ö–£–õ–Ø–†–ù–´–• –°–í–û–ô–°–¢–í")
        logger.info("=" * 60)
        
        try:
            pipeline = MolecularPropertyPredictionPipeline()
            
            for cycle in range(cycles):
                logger.info(f"–¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è {cycle + 1}/{cycles}")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                pipeline.load_and_process_data(dataset_name)
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
                X_desc, y_desc = pipeline.prepare_traditional_features('NR-AR')
                X_fp, y_fp = pipeline.prepare_fingerprint_features('NR-AR')
                graphs, y_graph = pipeline.prepare_graph_data('NR-AR')
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                models_dir = Path('biochemistry_molecules/models')
                if models_dir.exists() and any(models_dir.glob('*.pkl')):
                    pipeline.model_trainer.load_models()
                
                # –û–±—É—á–∞–µ–º —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
                pipeline.train_traditional_models(X_desc, y_desc, 'classification')
                pipeline.train_traditional_models(X_fp, y_fp, 'classification')
                
                # –û–±—É—á–∞–µ–º –≥—Ä–∞—Ñ–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
                pipeline.train_graph_models(graphs, y_graph, 'classification')
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏
                pipeline.model_trainer.save_models()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
                self.training_history['molecular']['cycles'] += 1
                self.training_history['molecular']['last_training'] = datetime.now().isoformat()
                
                logger.info(f"‚úÖ –¶–∏–∫–ª {cycle + 1} –∑–∞–≤–µ—Ä—à–µ–Ω")
            
            self.save_training_history()
            logger.info("‚úÖ –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏: {e}")
            return False
    
    def incremental_train_small_ml(self, task_types=['classification', 'regression'], cycles=2):
        """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–∞–ª–æ–≥–æ ML –ø—Ä–æ–µ–∫—Ç–∞"""
        logger.info("=" * 60)
        logger.info("–ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ú–ê–õ–û–ì–û ML –ü–†–û–ï–ö–¢–ê")
        logger.info("=" * 60)
        
        try:
            pipeline = MLPipeline()
            
            for cycle in range(cycles):
                logger.info(f"–¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è {cycle + 1}/{cycles}")
                
                for task_type in task_types:
                    logger.info(f"–û–±—É—á–µ–Ω–∏–µ –¥–ª—è –∑–∞–¥–∞—á–∏: {task_type}")
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
                    pipeline.generate_data(task_type=task_type, n_samples=1000)
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    X, y = pipeline.preprocess_data()
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                    models_dir = Path('small_ml_project/models')
                    if models_dir.exists() and any(models_dir.glob('*.pkl')):
                        pipeline.model_trainer.load_models()
                    
                    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏
                    X_train, X_val, X_test, y_train, y_val, y_test = pipeline.model_trainer.prepare_data(
                        X, y, task_type=task_type
                    )
                    
                    pipeline.model_trainer.train_all_models(X_train, y_train, X_val, y_val, task_type)
                    pipeline.model_trainer.evaluate_all_models(X_test, y_test, task_type)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏
                    pipeline.model_trainer.save_models()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
                self.training_history['small_ml']['cycles'] += 1
                self.training_history['small_ml']['last_training'] = datetime.now().isoformat()
                
                logger.info(f"‚úÖ –¶–∏–∫–ª {cycle + 1} –∑–∞–≤–µ—Ä—à–µ–Ω")
            
            self.save_training_history()
            logger.info("‚úÖ –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–∞–ª–æ–≥–æ ML –ø—Ä–æ–µ–∫—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏: {e}")
            return False
    
    def run_incremental_training(self, cycles=3):
        """–ó–∞–ø—É—Å–∫ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤"""
        logger.info("üöÄ –ù–ê–ß–ê–õ–û –ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
        logger.info("=" * 80)
        
        start_time = time.time()
        
        # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è
        self.incremental_train_human_behavior(cycles=cycles)
        
        # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤
        self.incremental_train_molecular(cycles=cycles)
        
        # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–∞–ª–æ–≥–æ ML –ø—Ä–æ–µ–∫—Ç–∞
        self.incremental_train_small_ml(cycles=cycles)
        
        total_time = time.time() - start_time
        logger.info("=" * 80)
        logger.info(f"‚úÖ –ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        logger.info("=" * 80)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        self.generate_incremental_report()
    
    def generate_incremental_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏"""
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏...")
        
        report = f"""
# –û—Ç—á–µ—Ç –æ–± –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π ML
–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è

### Human Behavior Prediction
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏–∫–ª–æ–≤: {self.training_history['human_behavior']['cycles']}
- –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ: {self.training_history['human_behavior']['last_training']}

### Molecular Property Prediction
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏–∫–ª–æ–≤: {self.training_history['molecular']['cycles']}
- –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ: {self.training_history['molecular']['last_training']}

### Small ML Project
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏–∫–ª–æ–≤: {self.training_history['small_ml']['cycles']}
- –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ: {self.training_history['small_ml']['last_training']}

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

1. –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π
2. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
3. –†–µ–≥—É–ª—è—Ä–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–π—Ç–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
4. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
3. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–≤–µ–¥–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
"""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        with open('incremental_training_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info("–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ incremental_training_report.md")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    trainer = IncrementalTrainer()
    
    # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    trainer.run_incremental_training(cycles=3)

if __name__ == "__main__":
    main()