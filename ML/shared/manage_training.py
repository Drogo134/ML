#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π
"""

import os
import sys
import json
import argparse
import logging
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –ø—Ä–æ–µ–∫—Ç–∞–º
sys.path.append('human_behavior_prediction')
sys.path.append('biochemistry_molecules')
sys.path.append('small_ml_project')

from train_models import ModelTrainer
from incremental_training import IncrementalTrainer
from test_models import ModelTester

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training_management.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TrainingManager:
    def __init__(self):
        self.trainer = ModelTrainer()
        self.incremental_trainer = IncrementalTrainer()
        self.tester = ModelTester()
    
    def full_training(self, n_samples=10000, dataset_name='tox21'):
        """–ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        logger.info("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
        return self.trainer.run_full_training(n_samples, dataset_name)
    
    def incremental_training(self, cycles=3):
        """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"""
        logger.info("üîÑ –ó–ê–ü–£–°–ö –ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
        return self.incremental_trainer.run_incremental_training(cycles)
    
    def test_models(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        logger.info("üß™ –ó–ê–ü–£–°–ö –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ú–û–î–ï–õ–ï–ô")
        return self.tester.run_all_tests()
    
    def continue_training(self, project_name, additional_epochs=10):
        """–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è"""
        logger.info(f"‚ñ∂Ô∏è –ü–†–û–î–û–õ–ñ–ï–ù–ò–ï –û–ë–£–ß–ï–ù–ò–Ø: {project_name}")
        return self.trainer.continue_training(project_name, additional_epochs)
    
    def check_status(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        logger.info("üìä –ü–†–û–í–ï–†–ö–ê –°–¢–ê–¢–£–°–ê –û–ë–£–ß–ï–ù–ò–Ø")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—É—Å
        self.trainer.load_training_status()
        
        print("\n" + "=" * 60)
        print("–°–¢–ê–¢–£–° –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ï–ô")
        print("=" * 60)
        
        for project, status in self.trainer.training_status.items():
            print(f"\n{project.upper()}:")
            print(f"  –°—Ç–∞—Ç—É—Å: {status['status']}")
            print(f"  –ú–æ–¥–µ–ª–∏: {', '.join(status['models']) if status['models'] else '–ù–µ—Ç'}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π
        print("\n" + "=" * 60)
        print("–§–ê–ô–õ–´ –ú–û–î–ï–õ–ï–ô")
        print("=" * 60)
        
        projects = ['human_behavior_prediction', 'biochemistry_molecules', 'small_ml_project']
        
        for project in projects:
            models_dir = Path(project) / 'models'
            if models_dir.exists():
                model_files = list(models_dir.glob('*.pkl')) + list(models_dir.glob('*.h5'))
                print(f"\n{project}:")
                for model_file in model_files:
                    size = model_file.stat().st_size / 1024 / 1024  # MB
                    print(f"  {model_file.name}: {size:.2f} MB")
            else:
                print(f"\n{project}: –ù–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ models")
    
    def clean_models(self):
        """–û—á–∏—Å—Ç–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        logger.info("üßπ –û–ß–ò–°–¢–ö–ê –û–ë–£–ß–ï–ù–ù–´–• –ú–û–î–ï–õ–ï–ô")
        
        projects = ['human_behavior_prediction', 'biochemistry_molecules', 'small_ml_project']
        
        for project in projects:
            models_dir = Path(project) / 'models'
            if models_dir.exists():
                for model_file in models_dir.glob('*'):
                    if model_file.is_file():
                        model_file.unlink()
                        logger.info(f"–£–¥–∞–ª–µ–Ω: {model_file}")
        
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ç—É—Å
        if os.path.exists('training_status.json'):
            os.remove('training_status.json')
        
        if os.path.exists('training_history.json'):
            os.remove('training_history.json')
        
        logger.info("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    def backup_models(self):
        """–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        logger.info("üíæ –†–ï–ó–ï–†–í–ù–û–ï –ö–û–ü–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
        
        backup_dir = Path('backup') / datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        projects = ['human_behavior_prediction', 'biochemistry_molecules', 'small_ml_project']
        
        for project in projects:
            models_dir = Path(project) / 'models'
            if models_dir.exists():
                project_backup_dir = backup_dir / project
                project_backup_dir.mkdir(exist_ok=True)
                
                # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π
                import shutil
                for model_file in models_dir.glob('*'):
                    if model_file.is_file():
                        shutil.copy2(model_file, project_backup_dir)
                        logger.info(f"–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: {model_file} -> {project_backup_dir}")
        
        logger.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {backup_dir}")
    
    def restore_models(self, backup_path):
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        logger.info(f"üîÑ –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ò–ó: {backup_path}")
        
        backup_dir = Path(backup_path)
        if not backup_dir.exists():
            logger.error(f"‚ùå –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {backup_path}")
            return False
        
        projects = ['human_behavior_prediction', 'biochemistry_molecules', 'small_ml_project']
        
        for project in projects:
            project_backup_dir = backup_dir / project
            if project_backup_dir.exists():
                models_dir = Path(project) / 'models'
                models_dir.mkdir(parents=True, exist_ok=True)
                
                # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π
                import shutil
                for model_file in project_backup_dir.glob('*'):
                    if model_file.is_file():
                        shutil.copy2(model_file, models_dir)
                        logger.info(f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {model_file} -> {models_dir}")
        
        logger.info("‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        return True

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π ML')
    parser.add_argument('command', choices=[
        'full', 'incremental', 'test', 'continue', 'status', 'clean', 'backup', 'restore'
    ], help='–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è')
    parser.add_argument('--project', help='–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (–¥–ª—è continue)')
    parser.add_argument('--epochs', type=int, default=10, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (–¥–ª—è continue)')
    parser.add_argument('--cycles', type=int, default=3, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏–∫–ª–æ–≤ (–¥–ª—è incremental)')
    parser.add_argument('--samples', type=int, default=10000, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ (–¥–ª—è full)')
    parser.add_argument('--dataset', default='tox21', help='–ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–¥–ª—è full)')
    parser.add_argument('--backup-path', help='–ü—É—Ç—å –∫ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ (–¥–ª—è restore)')
    
    args = parser.parse_args()
    
    manager = TrainingManager()
    
    if args.command == 'full':
        manager.full_training(args.samples, args.dataset)
    elif args.command == 'incremental':
        manager.incremental_training(args.cycles)
    elif args.command == 'test':
        manager.test_models()
    elif args.command == 'continue':
        if not args.project:
            logger.error("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ø—Ä–æ–µ–∫—Ç –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è")
            return
        manager.continue_training(args.project, args.epochs)
    elif args.command == 'status':
        manager.check_status()
    elif args.command == 'clean':
        manager.clean_models()
    elif args.command == 'backup':
        manager.backup_models()
    elif args.command == 'restore':
        if not args.backup_path:
            logger.error("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
            return
        manager.restore_models(args.backup_path)

if __name__ == "__main__":
    main()