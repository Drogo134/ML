#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å AI API —Å–µ—Ä–≤–∏—Å–∞–º–∏
"""

import os
import json
import requests
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
import openai
from anthropic import Anthropic
import google.generativeai as genai

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIAPIManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ AI API"""
    
    def __init__(self):
        self.api_keys = self.load_api_keys()
        self.setup_apis()
    
    def load_api_keys(self) -> Dict[str, str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ API –∫–ª—é—á–µ–π –∏–∑ —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        config_file = 'ai_api_config.json'
        
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
            default_config = {
                "openai_api_key": "",
                "anthropic_api_key": "",
                "google_api_key": "",
                "huggingface_api_key": "",
                "cohere_api_key": "",
                "replicate_api_key": "",
                "stability_api_key": "",
                "midjourney_api_key": "",
                "custom_api_url": "",
                "custom_api_key": ""
            }
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, indent=2, ensure_ascii=False)
            
            logger.info(f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {config_file}")
            return default_config
    
    def setup_apis(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª–∏–µ–Ω—Ç–æ–≤"""
        # OpenAI
        if self.api_keys.get('openai_api_key'):
            openai.api_key = self.api_keys['openai_api_key']
            self.openai_client = openai.OpenAI(api_key=self.api_keys['openai_api_key'])
        else:
            self.openai_client = None
        
        # Anthropic
        if self.api_keys.get('anthropic_api_key'):
            self.anthropic_client = Anthropic(api_key=self.api_keys['anthropic_api_key'])
        else:
            self.anthropic_client = None
        
        # Google Gemini
        if self.api_keys.get('google_api_key'):
            genai.configure(api_key=self.api_keys['google_api_key'])
            self.google_model = genai.GenerativeModel('gemini-pro')
        else:
            self.google_model = None
    
    def update_api_key(self, service: str, api_key: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ API –∫–ª—é—á–∞"""
        self.api_keys[service] = api_key
        self.save_api_keys()
        self.setup_apis()
        logger.info(f"API –∫–ª—é—á –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞: {service}")
    
    def save_api_keys(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ API –∫–ª—é—á–µ–π"""
        with open('ai_api_config.json', 'w', encoding='utf-8') as f:
            json.dump(self.api_keys, f, indent=2, ensure_ascii=False)
    
    def test_api_connection(self, service: str) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API"""
        try:
            if service == 'openai' and self.openai_client:
                response = self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=1
                )
                return True
            
            elif service == 'anthropic' and self.anthropic_client:
                response = self.anthropic_client.messages.create(
                    model="claude-3-sonnet-20240229",
                    max_tokens=1,
                    messages=[{"role": "user", "content": "Test"}]
                )
                return True
            
            elif service == 'google' and self.google_model:
                response = self.google_model.generate_content("Test")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ {service}: {e}")
            return False
    
    def get_available_services(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤"""
        available = []
        
        if self.openai_client:
            available.append('openai')
        if self.anthropic_client:
            available.append('anthropic')
        if self.google_model:
            available.append('google')
        
        return available
    
    def generate_text(self, prompt: str, service: str = 'openai', **kwargs) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ AI API"""
        try:
            if service == 'openai' and self.openai_client:
                response = self.openai_client.chat.completions.create(
                    model=kwargs.get('model', 'gpt-3.5-turbo'),
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=kwargs.get('max_tokens', 1000),
                    temperature=kwargs.get('temperature', 0.7)
                )
                return response.choices[0].message.content
            
            elif service == 'anthropic' and self.anthropic_client:
                response = self.anthropic_client.messages.create(
                    model=kwargs.get('model', 'claude-3-sonnet-20240229'),
                    max_tokens=kwargs.get('max_tokens', 1000),
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            
            elif service == 'google' and self.google_model:
                response = self.google_model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=kwargs.get('max_tokens', 1000),
                        temperature=kwargs.get('temperature', 0.7)
                    )
                )
                return response.text
            
            else:
                logger.error(f"–°–µ—Ä–≤–∏—Å {service} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ {service}: {e}")
            return None
    
    def generate_embeddings(self, text: str, service: str = 'openai') -> Optional[List[float]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        try:
            if service == 'openai' and self.openai_client:
                response = self.openai_client.embeddings.create(
                    model="text-embedding-ada-002",
                    input=text
                )
                return response.data[0].embedding
            
            else:
                logger.error(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ {service} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ {service}: {e}")
            return None
    
    def analyze_data_with_ai(self, data: Any, analysis_type: str, service: str = 'openai') -> Optional[str]:
        """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é AI"""
        try:
            if analysis_type == 'behavior_patterns':
                prompt = f"""
                –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–≤–µ–¥–µ–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –≤—ã—è–≤–∏—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:
                
                {data}
                
                –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ:
                1. –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è
                2. –ê–Ω–æ–º–∞–ª–∏–∏ –∏ –≤—ã–±—Ä–æ—Å—ã
                3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
                4. –ü—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ –±—É–¥—É—â–µ–µ
                """
            
            elif analysis_type == 'molecular_properties':
                prompt = f"""
                –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –∏–Ω—Å–∞–π—Ç—ã:
                
                {data}
                
                –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ:
                1. –•–∏–º–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞
                2. –ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                3. –¢–æ–∫—Å–∏–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é
                """
            
            elif analysis_type == 'ml_results':
                prompt = f"""
                –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:
                
                {data}
                
                –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ:
                1. –û—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π
                2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
                3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
                4. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                """
            
            else:
                prompt = f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ: {data}"
            
            return self.generate_text(prompt, service)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
    
    def generate_synthetic_data(self, data_type: str, n_samples: int, service: str = 'openai') -> Optional[List[Dict]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if data_type == 'user_behavior':
                prompt = f"""
                –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ {n_samples} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π –æ –ø–æ–≤–µ–¥–µ–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
                –ö–∞–∂–¥–∞—è –∑–∞–ø–∏—Å—å –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
                - user_id: —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                - age: –≤–æ–∑—Ä–∞—Å—Ç (18-65)
                - gender: –ø–æ–ª (male/female)
                - income: –¥–æ—Ö–æ–¥ (30000-150000)
                - education: –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (high_school, bachelor, master, phd)
                - location: –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ (city, suburb, rural)
                - device_type: —Ç–∏–ø —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (mobile, desktop, tablet)
                - session_duration: –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏ (1-300 –º–∏–Ω—É—Ç)
                - pages_visited: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–µ—â–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (1-50)
                - purchase_intent: –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–∫—É–ø–∫–∏ (0-1)
                - will_purchase: —Å–æ–≤–µ—Ä—à–∏—Ç –ø–æ–∫—É–ø–∫—É (0/1)
                - churn_risk: —Ä–∏—Å–∫ –æ—Ç—Ç–æ–∫–∞ (0-1)
                - engagement_score: –æ—Ü–µ–Ω–∫–∞ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ (0-1)
                """
            
            elif data_type == 'molecular_data':
                prompt = f"""
                –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ {n_samples} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
                –ö–∞–∂–¥–∞—è –∑–∞–ø–∏—Å—å –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
                - molecule_id: —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –º–æ–ª–µ–∫—É–ª—ã
                - smiles: SMILES —Å—Ç—Ä–æ–∫–∞
                - molecular_weight: –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–π –≤–µ—Å (50-1000)
                - logp: –ª–∏–ø–æ—Ñ–∏–ª—å–Ω–æ—Å—Ç—å (-2 –¥–æ 6)
                - hbd: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–Ω–æ—Ä–æ–≤ –≤–æ–¥–æ—Ä–æ–¥–∞ (0-10)
                - hba: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ü–µ–ø—Ç–æ—Ä–æ–≤ –≤–æ–¥–æ—Ä–æ–¥–∞ (0-15)
                - tpsa: —Ç–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø–æ–ª—è—Ä–Ω–∞—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å (0-200)
                - rotatable_bonds: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ä–∞—â–∞—é—â–∏—Ö—Å—è —Å–≤—è–∑–µ–π (0-20)
                - aromatic_rings: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–ª–µ—Ü (0-5)
                - heavy_atoms: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—è–∂–µ–ª—ã—Ö –∞—Ç–æ–º–æ–≤ (5-100)
                - toxicity: —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å (0-1)
                - activity: –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (0-1)
                """
            
            else:
                prompt = f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ {n_samples} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π —Ç–∏–ø–∞ {data_type} –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON"
            
            response = self.generate_text(prompt, service, max_tokens=4000)
            
            if response:
                # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
                import re
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
                else:
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω JSON, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    return [{"data": response}]
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
    
    def enhance_predictions(self, predictions: List[float], context: str, service: str = 'openai') -> Optional[Dict]:
        """–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å –ø–æ–º–æ—â—å—é AI"""
        try:
            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:
            
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {predictions}
            –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}
            
            –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ:
            1. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            2. –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º
            3. –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
            """
            
            response = self.generate_text(prompt, service)
            
            if response:
                return {
                    "enhanced_predictions": predictions,
                    "confidence_scores": [0.8] * len(predictions),
                    "ai_analysis": response,
                    "recommendations": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å—é"
                }
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {e}")
            return None
    
    def generate_model_insights(self, model_performance: Dict, service: str = 'openai') -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        try:
            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã:
            
            –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:
            {json.dumps(model_performance, indent=2)}
            
            –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ:
            1. –û–±—â—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏
            2. –°–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
            3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
            4. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –º–µ—Ç—Ä–∏–∫
            5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏
            """
            
            return self.generate_text(prompt, service)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤: {e}")
            return None
    
    def create_ai_report(self, project_name: str, results: Dict, service: str = 'openai') -> Optional[str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ AI –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–µ–∫—Ç–µ"""
        try:
            prompt = f"""
            –°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–µ–∫—Ç–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:
            
            –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞: {project_name}
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {json.dumps(results, indent=2)}
            
            –û—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å:
            1. –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø—Ä–æ–µ–∫—Ç–∞
            2. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏
            4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            5. –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
            6. –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
            """
            
            return self.generate_text(prompt, service, max_tokens=2000)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è AI –æ—Ç—á–µ—Ç–∞: {e}")
            return None

class AIEnhancer:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è ML –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é AI"""
    
    def __init__(self):
        self.api_manager = AIAPIManager()
    
    def enhance_human_behavior_prediction(self, data: Any, predictions: List[float]) -> Dict:
        """–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞"""
        try:
            # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é AI
            ai_analysis = self.api_manager.analyze_data_with_ai(
                data, 'behavior_patterns', 'openai'
            )
            
            # –£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            enhanced_predictions = self.api_manager.enhance_predictions(
                predictions, "–ü—Ä–æ–≥–Ω–æ–∑ –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", 'openai'
            )
            
            return {
                "ai_analysis": ai_analysis,
                "enhanced_predictions": enhanced_predictions,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è: {e}")
            return {}
    
    def enhance_molecular_prediction(self, data: Any, predictions: List[float]) -> Dict:
        """–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤"""
        try:
            # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é AI
            ai_analysis = self.api_manager.analyze_data_with_ai(
                data, 'molecular_properties', 'openai'
            )
            
            # –£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            enhanced_predictions = self.api_manager.enhance_predictions(
                predictions, "–ü—Ä–æ–≥–Ω–æ–∑ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤", 'openai'
            )
            
            return {
                "ai_analysis": ai_analysis,
                "enhanced_predictions": enhanced_predictions,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤: {e}")
            return {}
    
    def enhance_ml_results(self, results: Dict) -> Dict:
        """–£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ML"""
        try:
            # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é AI
            ai_analysis = self.api_manager.analyze_data_with_ai(
                results, 'ml_results', 'openai'
            )
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
            insights = self.api_manager.generate_model_insights(results, 'openai')
            
            return {
                "ai_analysis": ai_analysis,
                "insights": insights,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ML: {e}")
            return {}
    
    def generate_synthetic_training_data(self, data_type: str, n_samples: int) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        try:
            return self.api_manager.generate_synthetic_data(data_type, n_samples, 'openai')
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return []
    
    def create_project_report(self, project_name: str, results: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–µ–∫—Ç–µ"""
        try:
            return self.api_manager.create_ai_report(project_name, results, 'openai')
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
            return "–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞"

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
    print("ü§ñ AI INTEGRATION MODULE")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä AI API
    api_manager = AIAPIManager()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
    available_services = api_manager.get_available_services()
    print(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ AI —Å–µ—Ä–≤–∏—Å—ã: {available_services}")
    
    if not available_services:
        print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ API –∫–ª—é—á–∏ –≤ ai_api_config.json")
        return
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    for service in available_services:
        if api_manager.test_api_connection(service):
            print(f"‚úÖ {service}: –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ")
        else:
            print(f"‚ùå {service}: –æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è")
    
    # –°–æ–∑–¥–∞–µ–º AI —É—Å–∏–ª–∏—Ç–µ–ª—å
    enhancer = AIEnhancer()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞
    if 'openai' in available_services:
        response = api_manager.generate_text("–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.", 'openai')
        if response:
            print(f"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: {response[:100]}...")
    
    print("\nüéâ AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")

if __name__ == "__main__":
    main()
