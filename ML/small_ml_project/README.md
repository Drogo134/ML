# Small ML Project - Comprehensive Pipeline

## Описание проекта

Комплексная система машинного обучения для решения различных задач классификации, регрессии и кластеризации. Проект демонстрирует современные подходы к машинному обучению с использованием нейронных сетей, традиционных алгоритмов и передовых методов оптимизации.

## Функции проекта

### Основные возможности
- Классификация данных с множественными алгоритмами
- Регрессионный анализ с различными метриками
- Кластеризация данных с оценкой качества
- Автоматическая генерация синтетических датасетов
- Сравнение производительности различных моделей

### Дополнительные функции
- Автоматическая инженерия признаков
- Оптимизация гиперпараметров
- Кросс-валидация и оценка моделей
- Визуализация результатов и данных
- AI-анализ результатов и создание отчетов

## Технологический стек

### Машинное обучение
- **TensorFlow 2.13** - глубокие нейронные сети
- **PyTorch 2.0** - альтернативный фреймворк
- **XGBoost 1.7.6** - градиентный бустинг
- **LightGBM 4.0.0** - быстрый градиентный бустинг
- **CatBoost 1.2.2** - категориальный бустинг
- **Scikit-learn 1.3.0** - традиционные алгоритмы

### Обработка данных
- **Pandas 2.0.3** - анализ и манипуляции с данными
- **NumPy 1.24.3** - численные вычисления
- **Feature-engine 1.6.2** - инженерия признаков
- **Imbalanced-learn 0.11.0** - работа с несбалансированными данными
- **MLxtend 0.22.0** - дополнительные инструменты ML

### Визуализация и анализ
- **Matplotlib 3.7.2** - базовые графики
- **Seaborn 0.12.2** - статистическая визуализация
- **Plotly 5.15.0** - интерактивные графики
- **Yellowbrick 1.5** - визуализация ML
- **SHAP 0.42.1** - интерпретация моделей
- **LIME 0.2.0.1** - локальная интерпретация

### Оптимизация
- **Optuna 3.3.0** - автоматическая оптимизация гиперпараметров
- **Hyperopt** - байесовская оптимизация
- **Scikit-optimize** - оптимизация с scikit-learn
- **Grid Search** - сеточный поиск
- **Random Search** - случайный поиск

### AI интеграция
- **OpenAI API** - GPT-3.5, GPT-4 для анализа
- **Anthropic API** - Claude для генерации отчетов
- **Google Gemini API** - альтернативный AI сервис

## Архитектура проекта

```
small_ml_project/
├── config.py                 # Конфигурация проекта
├── data_generator.py         # Генерация синтетических данных
├── models.py                 # Определение моделей ML
├── main.py                   # Основной пайплайн
├── requirements.txt          # Зависимости проекта
├── data/                     # Данные проекта
├── models/                   # Сохраненные модели
├── results/                  # Результаты и графики
└── logs/                     # Логи системы
```

## Установка и настройка

### Системные требования
- Python 3.8 или выше
- 8+ GB RAM (рекомендуется 16+ GB)
- 4+ CPU ядер (рекомендуется 8+ ядер)
- Windows 10+, macOS 10.14+, Ubuntu 18.04+

### Установка зависимостей
```bash
# Создание виртуального окружения
python -m venv venv
source venv/bin/activate  # Linux/Mac
# или
venv\Scripts\activate  # Windows

# Установка зависимостей
pip install -r requirements.txt
```

### Настройка AI интеграции (опционально)
```bash
# Настройка API ключей
python ../setup_ai_api.py

# Тестирование подключения
python ../test_ai_integration.py
```

## Использование

### Быстрый старт
```bash
# Запуск полного пайплайна
python main.py

# Или через общий скрипт
python ../quick_train.py
```

### Программное использование

#### Создание экземпляра пайплайна
```python
from main import MLPipeline

pipeline = MLPipeline()
```

#### Генерация данных
```python
# Генерация данных для классификации
data = pipeline.generate_data(task_type='classification', n_samples=1000)

# Генерация данных для регрессии
data = pipeline.generate_data(task_type='regression', n_samples=1000)

# Генерация данных для кластеризации
data = pipeline.generate_data(task_type='clustering', n_samples=1000)
```

#### Предобработка данных
```python
# Предобработка данных
X, y = pipeline.preprocess_data()

# Разделение на train/validation/test
X_train, X_val, X_test, y_train, y_val, y_test = pipeline.model_trainer.prepare_data(
    X, y, task_type='classification'
)
```

#### Обучение моделей
```python
# Обучение всех моделей
pipeline.model_trainer.train_all_models(X_train, y_train, X_val, y_val, 'classification')

# Оценка производительности
pipeline.model_trainer.evaluate_all_models(X_test, y_test, 'classification')
```

#### Визуализация результатов
```python
# Создание графиков
pipeline.create_visualizations(X_test, y_test)

# Создание интерактивного дашборда
pipeline.create_dashboard(results)
```

### Параметры конфигурации

#### Основные параметры
- `task_type` - тип задачи ('classification', 'regression', 'clustering')
- `n_samples` - количество образцов (по умолчанию: 1000)
- `n_features` - количество признаков (по умолчанию: 10)
- `test_size` - доля тестовых данных (по умолчанию: 0.2)
- `random_state` - случайное состояние для воспроизводимости

#### Параметры моделей
- `neural_network_epochs` - количество эпох для нейронной сети
- `neural_network_batch_size` - размер батча
- `random_forest_estimators` - количество деревьев Random Forest
- `xgboost_estimators` - количество деревьев XGBoost
- `lightgbm_estimators` - количество деревьев LightGBM

## Модели машинного обучения

### Нейронные сети
- **Глубокая нейронная сеть** - многослойный перцептрон
- **Архитектура**: Входной слой → Скрытые слои → Выходной слой
- **Активация**: ReLU, Sigmoid, Softmax
- **Оптимизатор**: Adam, AdamW
- **Функция потерь**: CrossEntropyLoss, MSELoss, BCELoss

### Градиентный бустинг
- **XGBoost** - экстремальный градиентный бустинг
- **LightGBM** - быстрый градиентный бустинг
- **CatBoost** - категориальный бустинг
- **Параметры**: автоматическая оптимизация через Optuna

### Традиционные алгоритмы
- **Random Forest** - случайный лес
- **Logistic Regression** - логистическая регрессия
- **SVM** - машина опорных векторов
- **Naive Bayes** - наивный байесовский классификатор
- **K-Nearest Neighbors** - метод k ближайших соседей

### Алгоритмы кластеризации
- **K-Means** - k-средних
- **DBSCAN** - плотностная кластеризация
- **Agglomerative Clustering** - иерархическая кластеризация
- **Gaussian Mixture** - смесь гауссовых распределений

## Генерация данных

### Синтетические датасеты
Система генерирует различные типы синтетических данных:

#### Классификация
- **Линейно разделимые данные** - простые случаи
- **Нелинейно разделимые данные** - сложные границы
- **Несбалансированные данные** - разные размеры классов
- **Многоклассовые данные** - несколько классов

#### Регрессия
- **Линейная регрессия** - линейные зависимости
- **Полиномиальная регрессия** - нелинейные зависимости
- **Случайный шум** - добавление шума
- **Выбросы** - аномальные значения

#### Кластеризация
- **Гауссовы кластеры** - сферические кластеры
- **Нелинейные кластеры** - сложные формы
- **Различные размеры** - кластеры разных размеров
- **Перекрывающиеся кластеры** - частичное перекрытие

### Аугментация данных
- **SMOTE** - синтетическое передискретизирование
- **ADASYN** - адаптивный синтетический отбор
- **Random Oversampling** - случайная передискретизация
- **Feature Noise** - добавление шума к признакам

## Оценка производительности

### Метрики классификации
- **Accuracy** - общая точность
- **Precision** - точность положительных предсказаний
- **Recall** - полнота положительных случаев
- **F1-Score** - гармоническое среднее precision и recall
- **AUC-ROC** - площадь под ROC кривой
- **AUC-PR** - площадь под Precision-Recall кривой
- **Confusion Matrix** - матрица ошибок

### Метрики регрессии
- **MSE** - среднеквадратичная ошибка
- **MAE** - средняя абсолютная ошибка
- **RMSE** - корень из среднеквадратичной ошибки
- **R²** - коэффициент детерминации
- **Adjusted R²** - скорректированный R²
- **Pearson R** - корреляция Пирсона

### Метрики кластеризации
- **Silhouette Score** - силуэтный коэффициент
- **Calinski-Harabasz Index** - индекс Калинского-Харабаша
- **Davies-Bouldin Index** - индекс Дэвиса-Болдина
- **Inertia** - инерция (сумма квадратов расстояний)

## Визуализация

### Графики данных
- **Scatter Plot** - диаграмма рассеяния
- **Histogram** - гистограмма
- **Box Plot** - ящичная диаграмма
- **Violin Plot** - скрипичная диаграмма
- **Pair Plot** - парные графики

### Графики моделей
- **Learning Curves** - кривые обучения
- **Validation Curves** - кривые валидации
- **ROC Curves** - ROC кривые
- **Precision-Recall Curves** - PR кривые
- **Feature Importance** - важность признаков

### Интерактивные дашборды
- **Plotly Dash** - веб-интерфейс
- **Jupyter Widgets** - интерактивные виджеты
- **Bokeh** - интерактивная визуализация
- **Streamlit** - быстрый прототипирование

## Оптимизация гиперпараметров

### Методы оптимизации
- **Grid Search** - сеточный поиск
- **Random Search** - случайный поиск
- **Bayesian Optimization** - байесовская оптимизация
- **Optuna** - автоматическая оптимизация
- **Hyperopt** - распределенная оптимизация

### Стратегии поиска
- **TPE (Tree-structured Parzen Estimator)** - оценщик Парзена
- **CMA-ES** - эволюционная стратегия
- **NSGA-II** - генетический алгоритм
- **Multi-objective Optimization** - многокритериальная оптимизация

## Кросс-валидация

### Стратегии валидации
- **K-Fold** - k-кратная кросс-валидация
- **Stratified K-Fold** - стратифицированная k-кратная
- **Leave-One-Out** - исключение одного объекта
- **Time Series Split** - временные ряды
- **Group K-Fold** - группированная k-кратная

### Оценка качества
- **Cross-validation Score** - оценка кросс-валидации
- **Learning Curves** - кривые обучения
- **Validation Curves** - кривые валидации
- **Bias-Variance Tradeoff** - компромисс смещение-дисперсия

## Мониторинг и обслуживание

### Отслеживание производительности
- **Model Performance** - производительность моделей
- **Data Drift** - дрифт данных
- **Concept Drift** - дрифт концепций
- **Model Degradation** - деградация моделей

### Логирование
- **Training Logs** - логи обучения
- **Prediction Logs** - логи предсказаний
- **Error Logs** - логи ошибок
- **Performance Logs** - логи производительности

## API интеграция

### Внешние API
- **Data Sources** - внешние источники данных
- **Model APIs** - API предобученных моделей
- **AI сервисы** - OpenAI, Anthropic, Google

### Внутренний API
- **REST API** - HTTP интерфейс
- **GraphQL** - гибкий API
- **WebSocket** - реальное время
- **Batch Processing** - пакетная обработка

## Развертывание

### Локальное развертывание
```bash
# Запуск локального сервера
python api_server.py

# Тестирование API
python test_api.py
```

### Docker развертывание
```bash
# Сборка образа
docker build -t small-ml-project .

# Запуск контейнера
docker run -p 8000:8000 small-ml-project
```

### Kubernetes развертывание
```bash
# Применение манифестов
kubectl apply -f ../k8s/

# Проверка статуса
kubectl get pods
```

## Примеры использования

### Базовый пример
```python
from main import MLPipeline

# Создание пайплайна
pipeline = MLPipeline()

# Генерация данных
data = pipeline.generate_data(task_type='classification', n_samples=1000)

# Предобработка
X, y = pipeline.preprocess_data()

# Обучение
pipeline.model_trainer.train_all_models(X, y, task_type='classification')

# Оценка
pipeline.model_trainer.evaluate_all_models(X, y, task_type='classification')
```

### Продвинутый пример с оптимизацией
```python
# Оптимизация гиперпараметров
best_params = pipeline.optimize_hyperparameters(X, y, 'classification')

# Обучение с лучшими параметрами
pipeline.model_trainer.train_with_params(X, y, best_params, 'classification')

# Создание визуализаций
pipeline.create_visualizations(X, y)
```

### Пример с AI интеграцией
```python
# AI анализ результатов
ai_analysis = pipeline.enhance_ml_results(results)

# Генерация синтетических данных через AI
synthetic_data = pipeline.ai_enhancer.generate_synthetic_training_data(
    'ml_data', n_samples=1000
)

# Создание AI отчета
report = pipeline.create_ai_report(results)
```

## Устранение неполадок

### Частые проблемы
1. **Ошибка памяти** - уменьшите n_samples или используйте batch processing
2. **Медленное обучение** - используйте GPU или уменьшите сложность моделей
3. **Низкая точность** - проверьте качество данных и настройте гиперпараметры
4. **Переобучение** - используйте регуляризацию и кросс-валидацию

### Логи и отладка
```bash
# Просмотр логов
tail -f logs/training.log

# Отладка моделей
python -c "from main import MLPipeline; pipeline = MLPipeline(); pipeline.debug_mode = True"
```

## Лицензия

Проект распространяется под лицензией MIT. См. файл LICENSE для подробностей.

## Контакты

Для вопросов и предложений обращайтесь к разработчикам проекта.

## Changelog

### Версия 1.0.0
- Первоначальный релиз
- Поддержка множественных задач ML
- Автоматическая генерация данных
- AI интеграция для анализа
- Система оптимизации
- Docker и Kubernetes поддержка