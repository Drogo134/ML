import pandas as pd
import numpy as np
import os
import warnings
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
sys.path.append('../shared')
from ai_integration import AIEnhancer

from config import Config
from data_generator import HumanBehaviorDataGenerator
from feature_engineering import FeatureEngineer
from models import ModelTrainer
from evaluation import ModelEvaluator

warnings.filterwarnings('ignore')

class HumanBehaviorPredictionPipeline:
    def __init__(self):
        self.config = Config()
        self.config.create_directories()
        
        self.data_generator = HumanBehaviorDataGenerator()
        self.feature_engineer = FeatureEngineer(self.config)
        self.model_trainer = ModelTrainer(self.config)
        self.evaluator = ModelEvaluator(self.config)
        self.ai_enhancer = AIEnhancer()
        
        self.data = None
        self.processed_data = None
        self.results = {}
        
    def generate_data(self, n_samples=10000, save_data=True):
        print("Generating synthetic human behavior data...")
        self.data = self.data_generator.generate_dataset(n_samples)
        
        if save_data:
            data_path = self.config.DATA_DIR / "human_behavior_data.csv"
            self.data.to_csv(data_path, index=False)
            print(f"Data saved to {data_path}")
        
        print(f"Generated dataset with shape: {self.data.shape}")
        return self.data
    
    def load_data(self, file_path=None):
        if file_path is None:
            file_path = self.config.DATA_DIR / "human_behavior_data.csv"
        
        if os.path.exists(file_path):
            self.data = pd.read_csv(file_path)
            print(f"Loaded data with shape: {self.data.shape}")
        else:
            print("Data file not found. Generating new data...")
            self.generate_data()
        
        return self.data
    
    def prepare_features(self, target_column='will_purchase'):
        print("Engineering features...")
        
        feature_columns = [col for col in self.data.columns if col not in 
                          ['will_purchase', 'will_churn', 'engagement_level', 'lifetime_value']]
        
        X = self.data[feature_columns]
        y = self.data[target_column]
        
        self.processed_data = self.feature_engineer.engineer_features(
            self.data, target_col=target_column, fit=True
        )
        
        processed_feature_columns = [col for col in self.processed_data.columns 
                                   if col not in ['will_purchase', 'will_churn', 'engagement_level', 'lifetime_value']]
        
        X_processed = self.processed_data[processed_feature_columns]
        y_processed = self.processed_data[target_column]
        
        print(f"Processed features shape: {X_processed.shape}")
        return X_processed, y_processed
    
    def train_models(self, X, y, target_type='classification'):
        print("Training models...")
        
        X_train_scaled, X_val_scaled, X_test_scaled, X_train, X_val, X_test, y_train, y_val, y_test = \
            self.model_trainer.prepare_data(X, y)
        
        models_to_train = ['xgboost', 'lightgbm', 'neural_network']
        
        for model_name in models_to_train:
            print(f"Training {model_name}...")
            
            if model_name == 'neural_network':
                model = self.model_trainer.train_neural_network(
                    X_train_scaled, y_train, X_val_scaled, y_val, target_type
                )
            elif model_name == 'xgboost':
                model = self.model_trainer.train_xgboost(
                    X_train, y_train, X_val, y_val, target_type
                )
            elif model_name == 'lightgbm':
                model = self.model_trainer.train_lightgbm(
                    X_train, y_train, X_val, y_val, target_type
                )
            
            if model_name == 'neural_network':
                y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)
                y_pred_proba = model.predict(X_test_scaled)
            else:
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
            
            metrics = self.evaluator.calculate_classification_metrics(y_test, y_pred, y_pred_proba)
            self.results[model_name] = metrics
            
            print(f"{model_name} - Accuracy: {metrics['accuracy']:.4f}, AUC: {metrics.get('auc', 'N/A')}")
        
        self.model_trainer.save_models()
        return X_test, y_test
    
    def evaluate_models(self, X_test, y_test):
        print("Evaluating models...")
        
        for model_name, model in self.model_trainer.models.items():
            if model_name == 'neural_network':
                y_pred = (model.predict(X_test) > 0.5).astype(int)
                y_pred_proba = model.predict(X_test)
            else:
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
            
            metrics = self.evaluator.calculate_classification_metrics(y_test, y_pred, y_pred_proba)
            self.results[model_name] = metrics
            
            print(f"\n{model_name} Results:")
            for metric, value in metrics.items():
                print(f"  {metric}: {value:.4f}")
    
    def create_visualizations(self, X_test, y_test):
        print("Creating visualizations...")
        
        results_dir = self.config.RESULTS_DIR
        
        for model_name, model in self.model_trainer.models.items():
            if model_name == 'neural_network':
                y_pred = (model.predict(X_test) > 0.5).astype(int)
                y_pred_proba = model.predict(X_test)
            else:
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
            
            self.evaluator.plot_confusion_matrix(
                y_test, y_pred, model_name, 
                save_path=results_dir / f"confusion_matrix_{model_name}.png"
            )
            
            if y_pred_proba is not None:
                self.evaluator.plot_roc_curve(
                    y_test, y_pred_proba, model_name,
                    save_path=results_dir / f"roc_curve_{model_name}.png"
                )
                
                self.evaluator.plot_precision_recall_curve(
                    y_test, y_pred_proba, model_name,
                    save_path=results_dir / f"precision_recall_{model_name}.png"
                )
            
            if hasattr(model, 'feature_importances_'):
                feature_names = [f"feature_{i}" for i in range(X_test.shape[1])]
                self.evaluator.plot_feature_importance(
                    feature_names, model.feature_importances_, model_name,
                    save_path=results_dir / f"feature_importance_{model_name}.png"
                )
    
    def run_full_pipeline(self, n_samples=10000, target_column='will_purchase'):
        print("Starting Human Behavior Prediction Pipeline...")
        print("=" * 50)
        
        self.generate_data(n_samples)
        X, y = self.prepare_features(target_column)
        X_test, y_test = self.train_models(X, y)
        self.evaluate_models(X_test, y_test)
        self.create_visualizations(X_test, y_test)
        
        print("\n" + "=" * 50)
        print("Pipeline completed successfully!")
        
        results_df = pd.DataFrame(self.results).T
        print("\nFinal Results:")
        print(results_df)
        
        results_df.to_csv(self.config.RESULTS_DIR / "model_results.csv")
        
        return results_df
    
    def enhance_with_ai(self, X_test, y_test, predictions=None):
        """–£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é AI"""
        print("\nü§ñ AI Enhancement for Human Behavior Prediction")
        print("=" * 50)
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞
            sample_data = {
                "data_shape": X_test.shape,
                "target_distribution": np.bincount(y_test).tolist(),
                "feature_statistics": {
                    "mean": np.mean(X_test, axis=0).tolist()[:5],  # –ü–µ—Ä–≤—ã–µ 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    "std": np.std(X_test, axis=0).tolist()[:5]
                }
            }
            
            # AI –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
            ai_analysis = self.ai_enhancer.enhance_human_behavior_prediction(
                sample_data, predictions if predictions is not None else []
            )
            
            if ai_analysis:
                print("‚úÖ AI –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º AI –∞–Ω–∞–ª–∏–∑
                ai_results_dir = self.config.RESULTS_DIR / "ai_analysis"
                ai_results_dir.mkdir(exist_ok=True)
                
                with open(ai_results_dir / "behavior_analysis.txt", "w", encoding="utf-8") as f:
                    f.write(ai_analysis.get("ai_analysis", "AI –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"))
                
                print(f"AI –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {ai_results_dir}")
                return ai_analysis
            else:
                print("‚ùå –û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}")
            return None
    
    def generate_ai_insights(self, model_performance):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è AI –∏–Ω—Å–∞–π—Ç–æ–≤ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        try:
            insights = self.ai_enhancer.enhance_ml_results(model_performance)
            
            if insights and insights.get("insights"):
                print("‚úÖ AI –∏–Ω—Å–∞–π—Ç—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Å–∞–π—Ç—ã
                ai_results_dir = self.config.RESULTS_DIR / "ai_analysis"
                ai_results_dir.mkdir(exist_ok=True)
                
                with open(ai_results_dir / "model_insights.txt", "w", encoding="utf-8") as f:
                    f.write(insights["insights"])
                
                return insights
            else:
                print("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ AI –∏–Ω—Å–∞–π—Ç–æ–≤")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ AI –∏–Ω—Å–∞–π—Ç–æ–≤: {e}")
            return None
    
    def create_ai_report(self, results):
        """–°–æ–∑–¥–∞–Ω–∏–µ AI –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–µ–∫—Ç–µ"""
        try:
            report = self.ai_enhancer.create_project_report(
                "Human Behavior Prediction System", results
            )
            
            if report:
                print("‚úÖ AI –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
                ai_results_dir = self.config.RESULTS_DIR / "ai_analysis"
                ai_results_dir.mkdir(exist_ok=True)
                
                with open(ai_results_dir / "ai_report.md", "w", encoding="utf-8") as f:
                    f.write(report)
                
                return report
            else:
                print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è AI –æ—Ç—á–µ—Ç–∞")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è AI –æ—Ç—á–µ—Ç–∞: {e}")
            return None

def main():
    pipeline = HumanBehaviorPredictionPipeline()
    
    results = pipeline.run_full_pipeline(n_samples=10000)
    
    print("\nResults saved to:")
    print(f"- Data: {pipeline.config.DATA_DIR}")
    print(f"- Models: {pipeline.config.MODELS_DIR}")
    print(f"- Results: {pipeline.config.RESULTS_DIR}")
    
    # AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
    print("\n" + "=" * 50)
    print("AI INTEGRATION")
    print("=" * 50)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º AI –∏–Ω—Å–∞–π—Ç—ã
    pipeline.generate_ai_insights(results.to_dict())
    
    # –°–æ–∑–¥–∞–µ–º AI –æ—Ç—á–µ—Ç
    pipeline.create_ai_report(results.to_dict())

if __name__ == "__main__":
    main()
